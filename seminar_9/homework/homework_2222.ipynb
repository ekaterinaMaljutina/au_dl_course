{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import re\n",
    "import urllib.request\n",
    "import os\n",
    "import random\n",
    "\n",
    "class ImdbMovieReviews:\n",
    "    DEFAULT_URL = \\\n",
    "        'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "    TOKEN_REGEX = re.compile(r'[A-Za-z]+|[!?.:,()]')\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._cache_dir = './imdb'\n",
    "        self._url = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "        \n",
    "        if not os.path.isfile(self._cache_dir):\n",
    "            urllib.request.urlretrieve(self._url, self._cache_dir)\n",
    "        self.filepath = self._cache_dir\n",
    "\n",
    "    def __iter__(self):\n",
    "        with tarfile.open(self.filepath) as archive:\n",
    "            items = archive.getnames()\n",
    "            for filename in archive.getnames():\n",
    "                if filename.startswith('aclImdb/train/pos/'):\n",
    "                    yield self._read(archive, filename), True\n",
    "                elif filename.startswith('aclImdb/train/neg/'):\n",
    "                    yield self._read(archive, filename), False\n",
    "                    \n",
    "    def _read(self, archive, filename):\n",
    "        with archive.extractfile(filename) as file_:\n",
    "            data = file_.read().decode('utf-8')\n",
    "            data = type(self).TOKEN_REGEX.findall(data)\n",
    "            data = [x.lower() for x in data]\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Spacy is my favourite nlp framework, which havu builtin word embeddings trains on wikipesia\n",
    "# from spacy.en import English\n",
    "import spacy\n",
    "\n",
    "class Embedding:\n",
    "    \n",
    "    def __init__(self):\n",
    "#          spaCy makes using word vectors very easy. \n",
    "#             The Lexeme , Token , Span  and Doc  classes all have a .vector property,\n",
    "#             which is a 1-dimensional numpy array of 32-bit floats:\n",
    "#         self.parser = English()\n",
    "        self.parser = spacy.load('en')\n",
    "#         self.parser = spacy.load('en_vectors_web_lg')\n",
    "#         self._length = length\n",
    "        self.dimensions = 300\n",
    "        \n",
    "    def __call__(self, sequence, length):\n",
    "        # DO I really need them to be equal length?\n",
    "        # Let's assume I'm not\n",
    "        data = np.zeros((length, self.dimensions))\n",
    "        # you can access known words from the parser's vocabulary\n",
    "        embedded = [self.parser.vocab[w].vector for w in sequence]\n",
    "        data[:len(sequence)] = embedded\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def preprocess_batched_split(iterator, embedding, batch_size):\n",
    "    iterator = iter(iterator)\n",
    "    while True:\n",
    "        batch = []\n",
    "        labelss = []\n",
    "        sentence_sizes_batch = []\n",
    "        for index in range(batch_size):\n",
    "            text, label = next(iterator)\n",
    "            sents = [list(y) for x, y in itertools.groupby(text, lambda z: z == '.') if not x]\n",
    "            sentence_sizes = [len(s) for s in sents]\n",
    "            text_embed = [embedding(sent) for sent in sents]\n",
    "            \n",
    "            batch.append(text_embed)\n",
    "            labelss.append(label)\n",
    "            sentence_sizes_batch.append(sentence_sizes)\n",
    "            \n",
    "        labels_batch = np.array(labelss, dtype=np.int32)\n",
    "        sent_per_doc = np.array([len(x) for x in sentence_sizes_batch])\n",
    "        words_per_sent_per_doc = np.array(sentence_sizes_batch)\n",
    "        yield np.array(batch), labels_batch, words_per_sent_per_doc, sent_per_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def preprocess_batched_split2(iterator, embedding, batch_size):\n",
    "    iterator = iter(iterator)\n",
    "    while True:\n",
    "        batch, labels_b = zip(*itertools.islice(iterator, batch_size))\n",
    "        \n",
    "        sents_b = [[list(y) for x, y in itertools.groupby(doc, lambda z: z == '.') if not x] for doc in batch]\n",
    "\n",
    "        sentence_sizes_b = [[len(sent) for sent in doc] for doc in sents_b]\n",
    "        sentence_size = max(map(max, sentence_sizes_b))\n",
    "        \n",
    "        document_sizes = np.array([len(doc) for doc in sentence_sizes_b], dtype=np.int32)\n",
    "        document_size = document_sizes.max()\n",
    "\n",
    "        sentence_sizes_np = np.zeros(shape=[batch_size, document_size], dtype=np.int32)\n",
    "        for bi, ds, ss in zip(range(sentence_sizes_np.shape[0]), document_sizes, sentence_sizes_b):\n",
    "            sentence_sizes_np[bi][:ds] = ss\n",
    "        \n",
    "        text_embed_b = np.zeros((batch_size, document_size, sentence_size, 300))\n",
    "        for i, ds, doc_sents in zip(range(text_embed_b.shape[0]), document_sizes, sents_b):\n",
    "            doc_sents_embed = np.array([embedding(sent, sentence_size) for sent in doc_sents])\n",
    "            text_embed_b[i][:ds] = doc_sents_embed\n",
    "        \n",
    "        yield text_embed_b, np.array(labels_b, dtype=np.int32), np.array(document_sizes), sentence_sizes_np, sents_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = list(ImdbMovieReviews())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0, '/home/emaljutina/au_dl_course/seminar_9/homework/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/emaljutina/au_dl_course/seminar_9/homework/',\n",
       " '',\n",
       " '/opt/anaconda3/lib/python36.zip',\n",
       " '/opt/anaconda3/lib/python3.6',\n",
       " '/opt/anaconda3/lib/python3.6/lib-dynload',\n",
       " '/opt/anaconda3/lib/python3.6/site-packages',\n",
       " '/opt/anaconda3/lib/python3.6/site-packages/Sphinx-1.5.6-py3.6.egg',\n",
       " '/opt/anaconda3/lib/python3.6/site-packages/setuptools-27.2.0-py3.6.egg',\n",
       " '/opt/anaconda3/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/emaljutina/.ipython']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "HanSequenceLabellingModel model_components\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport HanSequenceLabellingModel\n",
    "%aimport model_components\n",
    "%aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches_split = preprocess_batched_split2(reviews, Embedding(), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from HanSequenceLabellingModel import HanSequenceLabellingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HAN_model_1(session, restore_only=False):\n",
    "    \"\"\"Hierarhical Attention Network\"\"\"\n",
    "    import tensorflow as tf\n",
    "    try:\n",
    "        from tensorflow.contrib.rnn import GRUCell, MultiRNNCell, DropoutWrapper\n",
    "    except ImportError:\n",
    "        MultiRNNCell = tf.nn.rnn_cell.MultiRNNCell\n",
    "        GRUCell = tf.nn.rnn_cell.GRUCell\n",
    "    from bn_lstm import BNLSTMCell\n",
    "    from HanSequenceLabellingModel import HanSequenceLabellingModel\n",
    "\n",
    "    is_training = tf.placeholder(dtype=tf.bool, name='is_training')\n",
    "\n",
    "    cell = BNLSTMCell(80, is_training) # h-h batchnorm LSTMCell\n",
    "    cell = MultiRNNCell([cell]*5)\n",
    "\n",
    "    model = HanSequenceLabellingModel(\n",
    "            embedding_size=300,\n",
    "            classes=2,\n",
    "            word_cell=cell,\n",
    "            sentence_cell=cell,\n",
    "            word_output_size=300,\n",
    "            sentence_output_size=300,\n",
    "            learning_rate=0.001,\n",
    "            max_grad_norm=5.0,\n",
    "            dropout_keep_proba=0.5,\n",
    "            is_training=is_training,\n",
    "    )\n",
    "\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    checkpoint_dir = 'checkpoints'\n",
    "    checkpoint = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if checkpoint:\n",
    "        print(\"Reading model parameters from %s\" % checkpoint.model_checkpoint_path)\n",
    "        saver.restore(session, checkpoint.model_checkpoint_path)\n",
    "    elif restore_only:\n",
    "        raise FileNotFoundError(\"Cannot restore model\")\n",
    "    else:\n",
    "        print(\"Created model with fresh parameters\")\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        \n",
    "    return model, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_iters = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model parameters from checkpoints/checkpoint-120\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/checkpoint-120\n",
      "step 121, loss=0.751553, accuracy=0.4, t=21.05, inputs=(10, 13, 198, 300)\n",
      "step 122, loss=0.778923, accuracy=0.7, t=12.76, inputs=(10, 25, 118, 300)\n",
      "step 123, loss=0.692129, accuracy=0.5, t=8.29, inputs=(10, 18, 77, 300)\n",
      "step 124, loss=0.616933, accuracy=0.9, t=11.62, inputs=(10, 37, 91, 300)\n",
      "step 125, loss=0.971886, accuracy=0.4, t=8.4, inputs=(10, 28, 68, 300)\n",
      "step 126, loss=0.664534, accuracy=0.7, t=12.11, inputs=(10, 40, 96, 300)\n",
      "step 127, loss=0.673485, accuracy=0.6, t=10.5, inputs=(10, 27, 93, 300)\n",
      "step 128, loss=0.551665, accuracy=0.7, t=12.43, inputs=(10, 35, 104, 300)\n",
      "step 129, loss=0.553261, accuracy=0.9, t=9.49, inputs=(10, 28, 78, 300)\n",
      "step 130, loss=0.659165, accuracy=0.5, t=6.9, inputs=(10, 20, 59, 300)\n",
      "step 131, loss=0.542788, accuracy=0.9, t=8.84, inputs=(10, 17, 85, 300)\n",
      "step 132, loss=0.53501, accuracy=0.6, t=8.7, inputs=(10, 17, 86, 300)\n",
      "step 133, loss=0.546637, accuracy=0.8, t=10.16, inputs=(10, 39, 71, 300)\n",
      "step 134, loss=0.492016, accuracy=0.9, t=8.9, inputs=(10, 22, 80, 300)\n",
      "step 135, loss=0.575741, accuracy=0.6, t=10.6, inputs=(10, 20, 100, 300)\n",
      "step 136, loss=0.590845, accuracy=0.6, t=7.74, inputs=(10, 20, 69, 300)\n",
      "step 137, loss=0.681233, accuracy=0.4, t=5.42, inputs=(10, 20, 43, 300)\n",
      "step 138, loss=0.667578, accuracy=0.6, t=7.44, inputs=(10, 24, 65, 300)\n",
      "step 139, loss=0.687694, accuracy=0.8, t=7.91, inputs=(10, 28, 63, 300)\n",
      "step 140, loss=0.771323, accuracy=0.5, t=7.83, inputs=(10, 16, 74, 300)\n",
      "step 141, loss=0.537683, accuracy=0.8, t=12.98, inputs=(10, 29, 117, 300)\n",
      "step 142, loss=0.595955, accuracy=0.5, t=8.14, inputs=(10, 11, 82, 300)\n",
      "step 143, loss=0.538021, accuracy=0.8, t=9.46, inputs=(10, 34, 72, 300)\n",
      "step 144, loss=0.656427, accuracy=0.5, t=6.15, inputs=(10, 25, 50, 300)\n",
      "step 145, loss=0.536509, accuracy=0.9, t=7.18, inputs=(10, 30, 51, 300)\n",
      "step 146, loss=0.743273, accuracy=0.6, t=11.08, inputs=(10, 22, 104, 300)\n",
      "step 147, loss=0.935975, accuracy=0.5, t=10.09, inputs=(10, 20, 93, 300)\n",
      "step 148, loss=0.61337, accuracy=0.5, t=8.29, inputs=(10, 19, 76, 300)\n",
      "step 149, loss=0.729835, accuracy=0.5, t=7.81, inputs=(10, 17, 73, 300)\n",
      "step 150, loss=0.655441, accuracy=0.4, t=12.04, inputs=(10, 60, 65, 300)\n",
      "step 151, loss=0.586292, accuracy=0.7, t=13.27, inputs=(10, 19, 131, 300)\n",
      "step 152, loss=0.551019, accuracy=0.8, t=11.25, inputs=(10, 42, 83, 300)\n",
      "step 153, loss=0.724203, accuracy=0.5, t=14.96, inputs=(10, 62, 100, 300)\n",
      "step 154, loss=0.670325, accuracy=0.6, t=7.64, inputs=(10, 26, 61, 300)\n",
      "step 155, loss=0.677224, accuracy=0.6, t=12.96, inputs=(10, 41, 105, 300)\n",
      "step 156, loss=0.752367, accuracy=0.5, t=9.45, inputs=(10, 23, 84, 300)\n",
      "step 157, loss=0.65192, accuracy=0.6, t=8.9, inputs=(10, 37, 61, 300)\n",
      "step 158, loss=0.614767, accuracy=0.7, t=9.89, inputs=(10, 43, 70, 300)\n",
      "step 159, loss=0.650609, accuracy=0.6, t=9.19, inputs=(10, 32, 73, 300)\n",
      "step 160, loss=0.498862, accuracy=0.9, t=9.25, inputs=(10, 40, 63, 300)\n",
      "step 161, loss=0.620558, accuracy=0.9, t=9.84, inputs=(10, 52, 53, 300)\n",
      "step 162, loss=0.644023, accuracy=0.6, t=12.4, inputs=(10, 38, 101, 300)\n",
      "step 163, loss=0.788325, accuracy=0.6, t=9.48, inputs=(10, 23, 85, 300)\n",
      "step 164, loss=0.664612, accuracy=0.6, t=10.27, inputs=(10, 13, 105, 300)\n",
      "step 165, loss=0.807143, accuracy=0.5, t=8.05, inputs=(10, 28, 64, 300)\n",
      "step 166, loss=0.601452, accuracy=0.7, t=10.78, inputs=(10, 21, 102, 300)\n",
      "step 167, loss=0.623854, accuracy=0.6, t=10.28, inputs=(10, 37, 76, 300)\n",
      "step 168, loss=0.581381, accuracy=0.8, t=8.67, inputs=(10, 35, 62, 300)\n",
      "step 169, loss=0.461553, accuracy=0.8, t=9.48, inputs=(10, 25, 82, 300)\n",
      "step 170, loss=0.487218, accuracy=0.7, t=8.07, inputs=(10, 26, 71, 300)\n",
      "step 171, loss=0.529931, accuracy=0.6, t=9.97, inputs=(10, 13, 101, 300)\n",
      "step 172, loss=0.564799, accuracy=0.7, t=8.53, inputs=(10, 34, 63, 300)\n",
      "step 173, loss=0.571561, accuracy=0.8, t=9.19, inputs=(10, 27, 78, 300)\n",
      "step 174, loss=0.677691, accuracy=0.6, t=23.61, inputs=(10, 28, 239, 300)\n",
      "step 175, loss=0.595206, accuracy=0.8, t=11.8, inputs=(10, 40, 91, 300)\n",
      "step 176, loss=0.620452, accuracy=0.7, t=7.6, inputs=(10, 25, 62, 300)\n",
      "step 177, loss=0.512911, accuracy=0.7, t=11.81, inputs=(10, 23, 111, 300)\n",
      "step 178, loss=0.499246, accuracy=0.9, t=15.25, inputs=(10, 47, 124, 300)\n",
      "step 179, loss=0.770431, accuracy=0.4, t=10.42, inputs=(10, 23, 95, 300)\n",
      "step 180, loss=0.534124, accuracy=0.8, t=8.76, inputs=(10, 26, 73, 300)\n",
      "step 181, loss=0.715841, accuracy=0.5, t=13.96, inputs=(10, 49, 101, 300)\n",
      "step 182, loss=0.578028, accuracy=0.7, t=13.05, inputs=(10, 25, 123, 300)\n",
      "step 183, loss=0.710318, accuracy=0.4, t=7.23, inputs=(10, 29, 53, 300)\n",
      "step 184, loss=0.750345, accuracy=0.6, t=9.01, inputs=(10, 25, 77, 300)\n",
      "step 185, loss=0.772839, accuracy=0.6, t=7.49, inputs=(10, 33, 52, 300)\n",
      "step 186, loss=0.476072, accuracy=0.9, t=6.95, inputs=(10, 20, 59, 300)\n",
      "step 187, loss=0.602216, accuracy=0.5, t=14.02, inputs=(10, 44, 113, 300)\n",
      "step 188, loss=0.686423, accuracy=0.7, t=9.08, inputs=(10, 23, 79, 300)\n",
      "step 189, loss=0.521822, accuracy=0.7, t=14.45, inputs=(10, 20, 142, 300)\n",
      "step 190, loss=0.847649, accuracy=0.4, t=6.8, inputs=(10, 20, 58, 300)\n",
      "step 191, loss=0.468406, accuracy=0.9, t=10.83, inputs=(10, 45, 72, 300)\n",
      "step 192, loss=0.385888, accuracy=0.9, t=13.13, inputs=(10, 24, 125, 300)\n",
      "step 193, loss=0.716918, accuracy=0.7, t=9.15, inputs=(10, 36, 63, 300)\n",
      "step 194, loss=0.66495, accuracy=0.6, t=6.89, inputs=(10, 15, 63, 300)\n",
      "step 195, loss=0.469568, accuracy=0.8, t=7.31, inputs=(10, 17, 67, 300)\n",
      "step 196, loss=0.529047, accuracy=0.6, t=7.75, inputs=(10, 23, 64, 300)\n",
      "step 197, loss=0.775575, accuracy=0.6, t=10.11, inputs=(10, 26, 87, 300)\n",
      "step 198, loss=0.446915, accuracy=0.8, t=10.34, inputs=(10, 24, 92, 300)\n",
      "step 199, loss=0.483692, accuracy=0.9, t=7.27, inputs=(10, 23, 59, 300)\n",
      "step 200, loss=0.6102, accuracy=0.5, t=6.95, inputs=(10, 17, 62, 300)\n",
      "step 201, loss=0.465913, accuracy=0.8, t=6.5, inputs=(10, 21, 54, 300)\n",
      "step 202, loss=0.636059, accuracy=0.6, t=12.27, inputs=(10, 35, 102, 300)\n",
      "step 203, loss=0.645305, accuracy=0.8, t=12.98, inputs=(10, 45, 96, 300)\n",
      "step 204, loss=0.596447, accuracy=0.7, t=7.35, inputs=(10, 31, 52, 300)\n",
      "step 205, loss=0.505283, accuracy=0.7, t=11.29, inputs=(10, 23, 105, 300)\n",
      "step 206, loss=0.707997, accuracy=0.5, t=6.43, inputs=(10, 22, 52, 300)\n",
      "step 207, loss=0.407747, accuracy=0.9, t=9.31, inputs=(10, 33, 71, 300)\n",
      "step 208, loss=0.550445, accuracy=0.7, t=9.58, inputs=(10, 15, 94, 300)\n",
      "step 209, loss=0.495746, accuracy=0.8, t=10.42, inputs=(10, 25, 90, 300)\n",
      "step 210, loss=0.480488, accuracy=0.8, t=15.44, inputs=(10, 49, 116, 300)\n",
      "step 211, loss=0.480691, accuracy=0.8, t=12.75, inputs=(10, 21, 120, 300)\n",
      "step 212, loss=0.587809, accuracy=0.8, t=11.78, inputs=(10, 31, 101, 300)\n",
      "step 213, loss=0.346187, accuracy=1.0, t=6.99, inputs=(10, 18, 62, 300)\n",
      "step 214, loss=0.355427, accuracy=0.9, t=6.7, inputs=(10, 27, 48, 300)\n",
      "step 215, loss=0.334514, accuracy=1.0, t=14.0, inputs=(10, 36, 118, 300)\n",
      "step 216, loss=0.857026, accuracy=0.6, t=6.29, inputs=(10, 16, 59, 300)\n",
      "step 217, loss=0.510728, accuracy=0.8, t=13.45, inputs=(10, 55, 85, 300)\n",
      "step 218, loss=0.458028, accuracy=0.7, t=8.45, inputs=(10, 25, 69, 300)\n",
      "step 219, loss=0.55544, accuracy=0.5, t=11.0, inputs=(10, 21, 102, 300)\n",
      "step 220, loss=0.196621, accuracy=1.0, t=9.31, inputs=(10, 20, 85, 300)\n",
      "step 221, loss=0.286078, accuracy=1.0, t=19.47, inputs=(10, 36, 182, 300)\n",
      "step 222, loss=0.34525, accuracy=0.9, t=10.16, inputs=(10, 55, 53, 300)\n",
      "step 223, loss=0.366791, accuracy=0.9, t=9.74, inputs=(10, 30, 81, 300)\n",
      "step 224, loss=0.750488, accuracy=0.5, t=13.01, inputs=(10, 47, 96, 300)\n",
      "step 225, loss=0.339112, accuracy=0.9, t=6.83, inputs=(10, 26, 52, 300)\n",
      "step 226, loss=0.457087, accuracy=0.9, t=9.51, inputs=(10, 35, 73, 300)\n",
      "step 227, loss=0.631621, accuracy=0.8, t=5.49, inputs=(10, 16, 50, 300)\n",
      "step 228, loss=1.0942, accuracy=0.6, t=9.19, inputs=(10, 36, 67, 300)\n",
      "step 229, loss=0.703282, accuracy=0.7, t=9.8, inputs=(10, 43, 73, 300)\n",
      "step 230, loss=0.957151, accuracy=0.4, t=8.25, inputs=(10, 32, 64, 300)\n",
      "step 231, loss=0.286488, accuracy=0.8, t=9.58, inputs=(10, 20, 89, 300)\n",
      "step 232, loss=0.648334, accuracy=0.7, t=11.67, inputs=(10, 25, 111, 300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 233, loss=0.671095, accuracy=0.8, t=7.36, inputs=(10, 27, 56, 300)\n",
      "step 234, loss=0.393245, accuracy=0.8, t=11.56, inputs=(10, 19, 113, 300)\n",
      "step 235, loss=0.327059, accuracy=0.8, t=10.63, inputs=(10, 33, 87, 300)\n",
      "step 236, loss=0.342848, accuracy=0.9, t=10.36, inputs=(10, 25, 92, 300)\n",
      "step 237, loss=0.925362, accuracy=0.6, t=9.11, inputs=(10, 16, 90, 300)\n",
      "step 238, loss=0.311881, accuracy=0.9, t=6.95, inputs=(10, 21, 58, 300)\n",
      "step 239, loss=0.234265, accuracy=0.9, t=17.21, inputs=(10, 17, 176, 300)\n",
      "step 240, loss=0.305449, accuracy=0.9, t=11.96, inputs=(10, 43, 87, 300)\n",
      "step 241, loss=0.753397, accuracy=0.5, t=12.64, inputs=(10, 26, 114, 300)\n",
      "step 242, loss=0.262574, accuracy=1.0, t=7.15, inputs=(10, 29, 50, 300)\n",
      "step 243, loss=0.433611, accuracy=0.7, t=9.52, inputs=(10, 26, 83, 300)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-a87af5890dc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         ], feed_dict=fd)\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mtd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "with tf.Session(config=config) as s:\n",
    "    model, saver = HAN_model_1(s)\n",
    "    tflog_dir = 'tf_logs'\n",
    "    summary_writer = tf.summary.FileWriter(tflog_dir, graph=tf.get_default_graph())\n",
    "\n",
    "    for data, labels_batch, sent_per_doc, words_per_sent_per_doc, _ in batches_split:\n",
    "\n",
    "        fd = {\n",
    "            model.is_training: True,\n",
    "            model.inputs_embedded: data,\n",
    "            model.word_lengths: words_per_sent_per_doc,\n",
    "            model.sentence_lengths: sent_per_doc,\n",
    "            model.labels: labels_batch,\n",
    "            model.sample_weights: np.ones(shape=(10))\n",
    "        }\n",
    "\n",
    "        t0 = time.clock()\n",
    "        step, summaries, loss, accuracy, _ = s.run([\n",
    "                model.global_step,\n",
    "                model.summary,\n",
    "                model.loss,\n",
    "                model.accuracy,\n",
    "                model.train_op,\n",
    "        ], feed_dict=fd)\n",
    "        td = time.clock() - t0\n",
    "\n",
    "        summary_writer.add_summary(summaries, global_step=step)\n",
    "\n",
    "        checkpoint_frequency = 30\n",
    "        eval_frequency = 1\n",
    "        \n",
    "        if step >= max_iters:\n",
    "            break\n",
    "        \n",
    "        if step % 1 == 0:\n",
    "            print('step %s, loss=%s, accuracy=%s, t=%s, inputs=%s' % (step, loss, accuracy, round(td, 2), fd[model.inputs_embedded].shape))\n",
    "        if step != 0 and step % checkpoint_frequency == 0:\n",
    "#             print('checkpoint & graph meta')\n",
    "            checkpoint_path = 'checkpoints/checkpoint'\n",
    "            saver.save(s, checkpoint_path, global_step=step)\n",
    "#             print('checkpoint done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB color cube, 6x6x6:\n",
      "\u001b[48;5;16m000\u001b[0m\u001b[48;5;17m001\u001b[0m\u001b[48;5;18m002\u001b[0m\u001b[48;5;19m003\u001b[0m\u001b[48;5;20m004\u001b[0m\u001b[48;5;21m005\u001b[0m \u001b[48;5;52m100\u001b[0m\u001b[48;5;53m101\u001b[0m\u001b[48;5;54m102\u001b[0m\u001b[48;5;55m103\u001b[0m\u001b[48;5;56m104\u001b[0m\u001b[48;5;57m105\u001b[0m \u001b[48;5;88m200\u001b[0m\u001b[48;5;89m201\u001b[0m\u001b[48;5;90m202\u001b[0m\u001b[48;5;91m203\u001b[0m\u001b[48;5;92m204\u001b[0m\u001b[48;5;93m205\u001b[0m \u001b[48;5;124m300\u001b[0m\u001b[48;5;125m301\u001b[0m\u001b[48;5;126m302\u001b[0m\u001b[48;5;127m303\u001b[0m\u001b[48;5;128m304\u001b[0m\u001b[48;5;129m305\u001b[0m \u001b[48;5;160m400\u001b[0m\u001b[48;5;161m401\u001b[0m\u001b[48;5;162m402\u001b[0m\u001b[48;5;163m403\u001b[0m\u001b[48;5;164m404\u001b[0m\u001b[48;5;165m405\u001b[0m \u001b[48;5;196m500\u001b[0m\u001b[48;5;197m501\u001b[0m\u001b[48;5;198m502\u001b[0m\u001b[48;5;199m503\u001b[0m\u001b[48;5;200m504\u001b[0m\u001b[48;5;201m505\u001b[0m \n",
      "\u001b[48;5;22m010\u001b[0m\u001b[48;5;23m011\u001b[0m\u001b[48;5;24m012\u001b[0m\u001b[48;5;25m013\u001b[0m\u001b[48;5;26m014\u001b[0m\u001b[48;5;27m015\u001b[0m \u001b[48;5;58m110\u001b[0m\u001b[48;5;59m111\u001b[0m\u001b[48;5;60m112\u001b[0m\u001b[48;5;61m113\u001b[0m\u001b[48;5;62m114\u001b[0m\u001b[48;5;63m115\u001b[0m \u001b[48;5;94m210\u001b[0m\u001b[48;5;95m211\u001b[0m\u001b[48;5;96m212\u001b[0m\u001b[48;5;97m213\u001b[0m\u001b[48;5;98m214\u001b[0m\u001b[48;5;99m215\u001b[0m \u001b[48;5;130m310\u001b[0m\u001b[48;5;131m311\u001b[0m\u001b[48;5;132m312\u001b[0m\u001b[48;5;133m313\u001b[0m\u001b[48;5;134m314\u001b[0m\u001b[48;5;135m315\u001b[0m \u001b[48;5;166m410\u001b[0m\u001b[48;5;167m411\u001b[0m\u001b[48;5;168m412\u001b[0m\u001b[48;5;169m413\u001b[0m\u001b[48;5;170m414\u001b[0m\u001b[48;5;171m415\u001b[0m \u001b[48;5;202m510\u001b[0m\u001b[48;5;203m511\u001b[0m\u001b[48;5;204m512\u001b[0m\u001b[48;5;205m513\u001b[0m\u001b[48;5;206m514\u001b[0m\u001b[48;5;207m515\u001b[0m \n",
      "\u001b[48;5;28m020\u001b[0m\u001b[48;5;29m021\u001b[0m\u001b[48;5;30m022\u001b[0m\u001b[48;5;31m023\u001b[0m\u001b[48;5;32m024\u001b[0m\u001b[48;5;33m025\u001b[0m \u001b[48;5;64m120\u001b[0m\u001b[48;5;65m121\u001b[0m\u001b[48;5;66m122\u001b[0m\u001b[48;5;67m123\u001b[0m\u001b[48;5;68m124\u001b[0m\u001b[48;5;69m125\u001b[0m \u001b[48;5;100m220\u001b[0m\u001b[48;5;101m221\u001b[0m\u001b[48;5;102m222\u001b[0m\u001b[48;5;103m223\u001b[0m\u001b[48;5;104m224\u001b[0m\u001b[48;5;105m225\u001b[0m \u001b[48;5;136m320\u001b[0m\u001b[48;5;137m321\u001b[0m\u001b[48;5;138m322\u001b[0m\u001b[48;5;139m323\u001b[0m\u001b[48;5;140m324\u001b[0m\u001b[48;5;141m325\u001b[0m \u001b[48;5;172m420\u001b[0m\u001b[48;5;173m421\u001b[0m\u001b[48;5;174m422\u001b[0m\u001b[48;5;175m423\u001b[0m\u001b[48;5;176m424\u001b[0m\u001b[48;5;177m425\u001b[0m \u001b[48;5;208m520\u001b[0m\u001b[48;5;209m521\u001b[0m\u001b[48;5;210m522\u001b[0m\u001b[48;5;211m523\u001b[0m\u001b[48;5;212m524\u001b[0m\u001b[48;5;213m525\u001b[0m \n",
      "\u001b[48;5;34m030\u001b[0m\u001b[48;5;35m031\u001b[0m\u001b[48;5;36m032\u001b[0m\u001b[48;5;37m033\u001b[0m\u001b[48;5;38m034\u001b[0m\u001b[48;5;39m035\u001b[0m \u001b[48;5;70m130\u001b[0m\u001b[48;5;71m131\u001b[0m\u001b[48;5;72m132\u001b[0m\u001b[48;5;73m133\u001b[0m\u001b[48;5;74m134\u001b[0m\u001b[48;5;75m135\u001b[0m \u001b[48;5;106m230\u001b[0m\u001b[48;5;107m231\u001b[0m\u001b[48;5;108m232\u001b[0m\u001b[48;5;109m233\u001b[0m\u001b[48;5;110m234\u001b[0m\u001b[48;5;111m235\u001b[0m \u001b[48;5;142m330\u001b[0m\u001b[48;5;143m331\u001b[0m\u001b[48;5;144m332\u001b[0m\u001b[48;5;145m333\u001b[0m\u001b[48;5;146m334\u001b[0m\u001b[48;5;147m335\u001b[0m \u001b[48;5;178m430\u001b[0m\u001b[48;5;179m431\u001b[0m\u001b[48;5;180m432\u001b[0m\u001b[48;5;181m433\u001b[0m\u001b[48;5;182m434\u001b[0m\u001b[48;5;183m435\u001b[0m \u001b[48;5;214m530\u001b[0m\u001b[48;5;215m531\u001b[0m\u001b[48;5;216m532\u001b[0m\u001b[48;5;217m533\u001b[0m\u001b[48;5;218m534\u001b[0m\u001b[48;5;219m535\u001b[0m \n",
      "\u001b[48;5;40m040\u001b[0m\u001b[48;5;41m041\u001b[0m\u001b[48;5;42m042\u001b[0m\u001b[48;5;43m043\u001b[0m\u001b[48;5;44m044\u001b[0m\u001b[48;5;45m045\u001b[0m \u001b[48;5;76m140\u001b[0m\u001b[48;5;77m141\u001b[0m\u001b[48;5;78m142\u001b[0m\u001b[48;5;79m143\u001b[0m\u001b[48;5;80m144\u001b[0m\u001b[48;5;81m145\u001b[0m \u001b[48;5;112m240\u001b[0m\u001b[48;5;113m241\u001b[0m\u001b[48;5;114m242\u001b[0m\u001b[48;5;115m243\u001b[0m\u001b[48;5;116m244\u001b[0m\u001b[48;5;117m245\u001b[0m \u001b[48;5;148m340\u001b[0m\u001b[48;5;149m341\u001b[0m\u001b[48;5;150m342\u001b[0m\u001b[48;5;151m343\u001b[0m\u001b[48;5;152m344\u001b[0m\u001b[48;5;153m345\u001b[0m \u001b[48;5;184m440\u001b[0m\u001b[48;5;185m441\u001b[0m\u001b[48;5;186m442\u001b[0m\u001b[48;5;187m443\u001b[0m\u001b[48;5;188m444\u001b[0m\u001b[48;5;189m445\u001b[0m \u001b[48;5;220m540\u001b[0m\u001b[48;5;221m541\u001b[0m\u001b[48;5;222m542\u001b[0m\u001b[48;5;223m543\u001b[0m\u001b[48;5;224m544\u001b[0m\u001b[48;5;225m545\u001b[0m \n",
      "\u001b[48;5;46m050\u001b[0m\u001b[48;5;47m051\u001b[0m\u001b[48;5;48m052\u001b[0m\u001b[48;5;49m053\u001b[0m\u001b[48;5;50m054\u001b[0m\u001b[48;5;51m055\u001b[0m \u001b[48;5;82m150\u001b[0m\u001b[48;5;83m151\u001b[0m\u001b[48;5;84m152\u001b[0m\u001b[48;5;85m153\u001b[0m\u001b[48;5;86m154\u001b[0m\u001b[48;5;87m155\u001b[0m \u001b[48;5;118m250\u001b[0m\u001b[48;5;119m251\u001b[0m\u001b[48;5;120m252\u001b[0m\u001b[48;5;121m253\u001b[0m\u001b[48;5;122m254\u001b[0m\u001b[48;5;123m255\u001b[0m \u001b[48;5;154m350\u001b[0m\u001b[48;5;155m351\u001b[0m\u001b[48;5;156m352\u001b[0m\u001b[48;5;157m353\u001b[0m\u001b[48;5;158m354\u001b[0m\u001b[48;5;159m355\u001b[0m \u001b[48;5;190m450\u001b[0m\u001b[48;5;191m451\u001b[0m\u001b[48;5;192m452\u001b[0m\u001b[48;5;193m453\u001b[0m\u001b[48;5;194m454\u001b[0m\u001b[48;5;195m455\u001b[0m \u001b[48;5;226m550\u001b[0m\u001b[48;5;227m551\u001b[0m\u001b[48;5;228m552\u001b[0m\u001b[48;5;229m553\u001b[0m\u001b[48;5;230m554\u001b[0m\u001b[48;5;231m555\u001b[0m \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print('RGB color cube, 6x6x6:')\n",
    "# for green in range(6):\n",
    "#     for red in range(6):\n",
    "#         for blue in range(6):\n",
    "#             print_color('{}{}{}'.format(red, green, blue), bg=rgb(red, green, blue), end='')\n",
    "#         print(' ', end='')\n",
    "#     print()\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    BLACK,\n",
    "    RED,\n",
    "    GREEN,\n",
    "    YELLOW,\n",
    "    BLUE,\n",
    "    MAGENTA,\n",
    "    CYAN,\n",
    "    LIGHT_GRAY,\n",
    "    DARK_GRAY,\n",
    "    BRIGHT_RED,\n",
    "    BRIGHT_GREEN,\n",
    "    BRIGHT_YELLOW,\n",
    "    BRIGHT_BLUE,\n",
    "    BRIGHT_MAGENTA,\n",
    "    BRIGHT_CYAN,\n",
    "    WHITE,\n",
    ") = range(16)\n",
    "\n",
    "def rgb(red, green, blue):\n",
    "    \"\"\"\n",
    "    Calculate the palette index of a color in the 6x6x6 color cube.\n",
    "    The red, green and blue arguments may range from 0 to 5.\n",
    "    \"\"\"\n",
    "    return 16 + (red * 36) + (green * 6) + blue\n",
    "\n",
    "def gray(value):\n",
    "    \"\"\"\n",
    "    Calculate the palette index of a color in the grayscale ramp.\n",
    "    The value argument may range from 0 to 23.\n",
    "    \"\"\"\n",
    "    return 232 + value\n",
    "\n",
    "def set_color(fg=None, bg=None):\n",
    "    \"\"\"\n",
    "    Print escape codes to set the terminal color.\n",
    "    fg and bg are indices into the color palette for the foreground and\n",
    "    background colors.\n",
    "    \"\"\"\n",
    "    print(_set_color(fg, bg), end='')\n",
    "\n",
    "def _set_color(fg=None, bg=None):\n",
    "    result = ''\n",
    "    if fg:\n",
    "        result += '\\x1b[38;5;%dm' % fg\n",
    "    if bg:\n",
    "        result += '\\x1b[48;5;%dm' % bg\n",
    "    return result\n",
    "\n",
    "def reset_color():\n",
    "    \"\"\"\n",
    "    Reset terminal color to default.\n",
    "    \"\"\"\n",
    "    print(_reset_color(), end='')\n",
    "\n",
    "def _reset_color():\n",
    "    return '\\x1b[0m'\n",
    "\n",
    "def print_color(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Print function, with extra arguments fg and bg to set colors.\n",
    "    \"\"\"\n",
    "    fg = kwargs.pop('fg', None)\n",
    "    bg = kwargs.pop('bg', None)\n",
    "    set_color(fg, bg)\n",
    "    print(*args, **kwargs)\n",
    "    reset_color()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;5;229mtest \u001b[0m"
     ]
    }
   ],
   "source": [
    " print_color('test', bg=rgb(5, 5, 3), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model parameters from checkpoints/checkpoint-240\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/checkpoint-240\n",
      "\u001b[48;5;119mthis \u001b[0m\u001b[48;5;119mmovie \u001b[0m\u001b[48;5;119mis \u001b[0m\u001b[48;5;119msimilar \u001b[0m\u001b[48;5;119mto \u001b[0m\u001b[48;5;119mthe \u001b[0m\u001b[48;5;119mplay \u001b[0m\u001b[48;5;119mentitled \u001b[0m\u001b[48;5;119mblithe \u001b[0m\u001b[48;5;118mspirit \u001b[0m\u001b[48;5;118mwritten \u001b[0m\u001b[48;5;118mby \u001b[0m\u001b[48;5;119mnoel \u001b[0m\u001b[48;5;119mcoward \u001b[0m\n",
      "\u001b[48;5;119mthe \u001b[0m\u001b[48;5;119mplot \u001b[0m\u001b[48;5;119mof \u001b[0m\u001b[48;5;119ma \u001b[0m\u001b[48;5;119mghost \u001b[0m\u001b[48;5;119mwife \u001b[0m\u001b[48;5;119mand \u001b[0m\u001b[48;5;119ma \u001b[0m\u001b[48;5;119mmedium \u001b[0m\u001b[48;5;119mare \u001b[0m\u001b[48;5;118mstrongly \u001b[0m\u001b[48;5;118mlinked \u001b[0m\u001b[48;5;118mto \u001b[0m\u001b[48;5;118mcoward \u001b[0m\u001b[48;5;119ms \u001b[0m\u001b[48;5;119mwriting \u001b[0m\n",
      "\u001b[48;5;120mi \u001b[0m\u001b[48;5;120mm \u001b[0m\u001b[48;5;120msurprised \u001b[0m\u001b[48;5;120mthat \u001b[0m\u001b[48;5;120mmovies \u001b[0m\u001b[48;5;119mof \u001b[0m\u001b[48;5;119mthis \u001b[0m\u001b[48;5;119mnature \u001b[0m\u001b[48;5;119mdon \u001b[0m\u001b[48;5;118mt \u001b[0m\u001b[48;5;119macknowledge \u001b[0m\u001b[48;5;119mthe \u001b[0m\u001b[48;5;119moriginal \u001b[0m\u001b[48;5;119mwriter \u001b[0m\u001b[48;5;119ms \u001b[0m\u001b[48;5;119mconcept \u001b[0m\n",
      "\u001b[48;5;120mi \u001b[0m\u001b[48;5;120mrealize \u001b[0m\u001b[48;5;120mthat \u001b[0m\u001b[48;5;119mthe \u001b[0m\u001b[48;5;119mpublic \u001b[0m\u001b[48;5;119mmay \u001b[0m\u001b[48;5;119mnot \u001b[0m\u001b[48;5;119mbe \u001b[0m\u001b[48;5;119maware \u001b[0m\u001b[48;5;119mthat \u001b[0m\u001b[48;5;119mthis \u001b[0m\u001b[48;5;119mis \u001b[0m\u001b[48;5;119ma \u001b[0m\u001b[48;5;119mknockoff \u001b[0m\u001b[48;5;119mbut \u001b[0m\u001b[48;5;119mit \u001b[0m\u001b[48;5;119mis \u001b[0m\n",
      "\u001b[48;5;117mbr \u001b[0m\u001b[48;5;116mbr \u001b[0m\u001b[48;5;117msad \u001b[0m\n",
      "\u001b[48;5;119mthese \u001b[0m\u001b[48;5;119mmovies \u001b[0m\u001b[48;5;119mare \u001b[0m\u001b[48;5;119mso \u001b[0m\u001b[48;5;119mexpensive \u001b[0m\u001b[48;5;119mto \u001b[0m\u001b[48;5;119mproduce \u001b[0m\n",
      "\u001b[48;5;119mi \u001b[0m\u001b[48;5;119mdo \u001b[0m\u001b[48;5;119mperk \u001b[0m\u001b[48;5;119mup \u001b[0m\u001b[48;5;119mwhen \u001b[0m\u001b[48;5;119ma \u001b[0m\u001b[48;5;119mscreenplay \u001b[0m\u001b[48;5;119mis \u001b[0m\u001b[48;5;119moriginal \u001b[0m\n",
      "\u001b[48;5;120mi \u001b[0m\u001b[48;5;120meven \u001b[0m\u001b[48;5;120mperk \u001b[0m\u001b[48;5;120mup \u001b[0m\u001b[48;5;119mwhen \u001b[0m\u001b[48;5;119mit \u001b[0m\u001b[48;5;119ms \u001b[0m\u001b[48;5;119man \u001b[0m\u001b[48;5;119minnovative \u001b[0m\u001b[48;5;119mway \u001b[0m\u001b[48;5;119mto \u001b[0m\u001b[48;5;119mproduce \u001b[0m\u001b[48;5;119ma \u001b[0m\u001b[48;5;119mwork \u001b[0m\u001b[48;5;119mthat \u001b[0m\u001b[48;5;119mwas \u001b[0m\u001b[48;5;119mpreviously \u001b[0m\u001b[48;5;120mreleased \u001b[0m\n",
      "\u001b[48;5;119mthere \u001b[0m\u001b[48;5;119mwere \u001b[0m\u001b[48;5;119msome \u001b[0m\u001b[48;5;119msamples \u001b[0m\u001b[48;5;119mmentioned \u001b[0m\u001b[48;5;119m( \u001b[0m\u001b[48;5;119msuch \u001b[0m\u001b[48;5;119mas \u001b[0m\u001b[48;5;119mtopper \u001b[0m\u001b[48;5;119m, \u001b[0m\u001b[48;5;119metc \u001b[0m\n",
      "\u001b[48;5;119m) \u001b[0m\n",
      "\u001b[48;5;119mbr \u001b[0m\u001b[48;5;119mbr \u001b[0m\u001b[48;5;119mi \u001b[0m\u001b[48;5;119mrealize \u001b[0m\u001b[48;5;119mthat \u001b[0m\u001b[48;5;119mmovies \u001b[0m\u001b[48;5;119mare \u001b[0m\u001b[48;5;119mstill \u001b[0m\u001b[48;5;119ma \u001b[0m\u001b[48;5;119mcomparatively \u001b[0m\u001b[48;5;119maffordable \u001b[0m\u001b[48;5;119mform \u001b[0m\u001b[48;5;118mof \u001b[0m\u001b[48;5;118mentertainment \u001b[0m\n",
      "\u001b[48;5;119mhowever \u001b[0m\u001b[48;5;119m, \u001b[0m\u001b[48;5;119mi \u001b[0m\u001b[48;5;119mm \u001b[0m\u001b[48;5;119mnot \u001b[0m\u001b[48;5;119mplease \u001b[0m\u001b[48;5;119mwhen \u001b[0m\u001b[48;5;119mthe \u001b[0m\u001b[48;5;119mpublic \u001b[0m\u001b[48;5;119ms \u001b[0m\u001b[48;5;119mtaste \u001b[0m\u001b[48;5;119mis \u001b[0m\u001b[48;5;119mtaken \u001b[0m\u001b[48;5;119mfor \u001b[0m\u001b[48;5;119mgranted \u001b[0m\n",
      "\u001b[48;5;119min \u001b[0m\u001b[48;5;118mthis \u001b[0m\u001b[48;5;118msituation \u001b[0m\u001b[48;5;118m, \u001b[0m\u001b[48;5;118mthe \u001b[0m\u001b[48;5;118mpublic \u001b[0m\u001b[48;5;118ms \u001b[0m\u001b[48;5;118mtaste \u001b[0m\u001b[48;5;118mis \u001b[0m\u001b[48;5;118moverlooked \u001b[0m\n",
      "\u001b[48;5;119mbr \u001b[0m\u001b[48;5;119mbr \u001b[0m\u001b[48;5;118mi \u001b[0m\u001b[48;5;117mlook \u001b[0m\u001b[48;5;116mforward \u001b[0m\u001b[48;5;115mto \u001b[0m\u001b[48;5;116mbetter \u001b[0m\u001b[48;5;117mproduced \u001b[0m\u001b[48;5;118mmovie \u001b[0m\u001b[48;5;119mentertainment \u001b[0m\n",
      "\u001b[48;5;119mbr \u001b[0m\u001b[48;5;119mbr \u001b[0m\u001b[48;5;119min \u001b[0m\u001b[48;5;119mthis \u001b[0m\u001b[48;5;119mcase \u001b[0m\n",
      "\u001b[48;5;119mi \u001b[0m\u001b[48;5;119mrather \u001b[0m\u001b[48;5;119msee \u001b[0m\u001b[48;5;119mthe \u001b[0m\u001b[48;5;119mplay \u001b[0m\n",
      "\n",
      "\u001b[48;5;120mthis \u001b[0m\u001b[48;5;120mmovie \u001b[0m\u001b[48;5;120mis \u001b[0m\u001b[48;5;120msimilar \u001b[0m\u001b[48;5;120mto \u001b[0m\u001b[48;5;120mthe \u001b[0m\u001b[48;5;120mplay \u001b[0m\u001b[48;5;120mentitled \u001b[0m\u001b[48;5;120mblithe \u001b[0m\u001b[48;5;120mspirit \u001b[0m\u001b[48;5;120mwritten \u001b[0m\u001b[48;5;120mby \u001b[0m\u001b[48;5;120mnoel \u001b[0m\u001b[48;5;120mcoward \u001b[0m\n",
      "\u001b[48;5;120mthe \u001b[0m\u001b[48;5;120mplot \u001b[0m\u001b[48;5;120mof \u001b[0m\u001b[48;5;120ma \u001b[0m\u001b[48;5;120mghost \u001b[0m\u001b[48;5;120mwife \u001b[0m\u001b[48;5;120mand \u001b[0m\u001b[48;5;120ma \u001b[0m\u001b[48;5;120mmedium \u001b[0m\u001b[48;5;120mare \u001b[0m\u001b[48;5;120mstrongly \u001b[0m\u001b[48;5;120mlinked \u001b[0m\u001b[48;5;120mto \u001b[0m\u001b[48;5;120mcoward \u001b[0m\u001b[48;5;120ms \u001b[0m\u001b[48;5;120mwriting \u001b[0m\n",
      "\u001b[48;5;120mi \u001b[0m\u001b[48;5;120mm \u001b[0m\u001b[48;5;120msurprised \u001b[0m\u001b[48;5;120mthat \u001b[0m\u001b[48;5;120mmovies \u001b[0m\u001b[48;5;120mof \u001b[0m\u001b[48;5;120mthis \u001b[0m\u001b[48;5;120mnature \u001b[0m\u001b[48;5;120mdon \u001b[0m\u001b[48;5;120mt \u001b[0m\u001b[48;5;120macknowledge \u001b[0m\u001b[48;5;120mthe \u001b[0m\u001b[48;5;120moriginal \u001b[0m\u001b[48;5;120mwriter \u001b[0m\u001b[48;5;120ms \u001b[0m\u001b[48;5;120mconcept \u001b[0m\n",
      "\u001b[48;5;120mi \u001b[0m\u001b[48;5;120mrealize \u001b[0m\u001b[48;5;120mthat \u001b[0m\u001b[48;5;120mthe \u001b[0m\u001b[48;5;120mpublic \u001b[0m\u001b[48;5;120mmay \u001b[0m\u001b[48;5;120mnot \u001b[0m\u001b[48;5;120mbe \u001b[0m\u001b[48;5;120maware \u001b[0m\u001b[48;5;120mthat \u001b[0m\u001b[48;5;120mthis \u001b[0m\u001b[48;5;120mis \u001b[0m\u001b[48;5;120ma \u001b[0m\u001b[48;5;120mknockoff \u001b[0m\u001b[48;5;120mbut \u001b[0m\u001b[48;5;120mit \u001b[0m\u001b[48;5;120mis \u001b[0m\n",
      "\u001b[48;5;120mbr \u001b[0m\u001b[48;5;120mbr \u001b[0m\u001b[48;5;120msad \u001b[0m\n",
      "\u001b[48;5;120mthese \u001b[0m\u001b[48;5;120mmovies \u001b[0m\u001b[48;5;120mare \u001b[0m\u001b[48;5;120mso \u001b[0m\u001b[48;5;120mexpensive \u001b[0m\u001b[48;5;120mto \u001b[0m\u001b[48;5;120mproduce \u001b[0m\n",
      "\u001b[48;5;120mi \u001b[0m\u001b[48;5;120mdo \u001b[0m\u001b[48;5;120mperk \u001b[0m\u001b[48;5;120mup \u001b[0m\u001b[48;5;120mwhen \u001b[0m\u001b[48;5;120ma \u001b[0m\u001b[48;5;120mscreenplay \u001b[0m\u001b[48;5;120mis \u001b[0m\u001b[48;5;120moriginal \u001b[0m\n",
      "\u001b[48;5;120mi \u001b[0m\u001b[48;5;120meven \u001b[0m\u001b[48;5;120mperk \u001b[0m\u001b[48;5;120mup \u001b[0m\u001b[48;5;120mwhen \u001b[0m\u001b[48;5;120mit \u001b[0m\u001b[48;5;120ms \u001b[0m\u001b[48;5;120man \u001b[0m\u001b[48;5;120minnovative \u001b[0m\u001b[48;5;120mway \u001b[0m\u001b[48;5;120mto \u001b[0m\u001b[48;5;120mproduce \u001b[0m\u001b[48;5;120ma \u001b[0m\u001b[48;5;120mwork \u001b[0m\u001b[48;5;120mthat \u001b[0m\u001b[48;5;120mwas \u001b[0m\u001b[48;5;120mpreviously \u001b[0m\u001b[48;5;120mreleased \u001b[0m\n",
      "\u001b[48;5;120mthere \u001b[0m\u001b[48;5;120mwere \u001b[0m\u001b[48;5;120msome \u001b[0m\u001b[48;5;120msamples \u001b[0m\u001b[48;5;120mmentioned \u001b[0m\u001b[48;5;120m( \u001b[0m\u001b[48;5;120msuch \u001b[0m\u001b[48;5;120mas \u001b[0m\u001b[48;5;120mtopper \u001b[0m\u001b[48;5;120m, \u001b[0m\u001b[48;5;120metc \u001b[0m\n",
      "\u001b[48;5;120m) \u001b[0m\n",
      "\u001b[48;5;120mbr \u001b[0m\u001b[48;5;120mbr \u001b[0m\u001b[48;5;120mi \u001b[0m\u001b[48;5;120mrealize \u001b[0m\u001b[48;5;120mthat \u001b[0m\u001b[48;5;120mmovies \u001b[0m\u001b[48;5;120mare \u001b[0m\u001b[48;5;120mstill \u001b[0m\u001b[48;5;120ma \u001b[0m\u001b[48;5;120mcomparatively \u001b[0m\u001b[48;5;120maffordable \u001b[0m\u001b[48;5;120mform \u001b[0m\u001b[48;5;120mof \u001b[0m\u001b[48;5;120mentertainment \u001b[0m\n",
      "\u001b[48;5;120mhowever \u001b[0m\u001b[48;5;120m, \u001b[0m\u001b[48;5;120mi \u001b[0m\u001b[48;5;120mm \u001b[0m\u001b[48;5;120mnot \u001b[0m\u001b[48;5;120mplease \u001b[0m\u001b[48;5;120mwhen \u001b[0m\u001b[48;5;120mthe \u001b[0m\u001b[48;5;120mpublic \u001b[0m\u001b[48;5;120ms \u001b[0m\u001b[48;5;120mtaste \u001b[0m\u001b[48;5;120mis \u001b[0m\u001b[48;5;120mtaken \u001b[0m\u001b[48;5;120mfor \u001b[0m\u001b[48;5;120mgranted \u001b[0m\n",
      "\u001b[48;5;120min \u001b[0m\u001b[48;5;120mthis \u001b[0m\u001b[48;5;120msituation \u001b[0m\u001b[48;5;120m, \u001b[0m\u001b[48;5;120mthe \u001b[0m\u001b[48;5;120mpublic \u001b[0m\u001b[48;5;120ms \u001b[0m\u001b[48;5;120mtaste \u001b[0m\u001b[48;5;120mis \u001b[0m\u001b[48;5;120moverlooked \u001b[0m\n",
      "\u001b[48;5;120mbr \u001b[0m\u001b[48;5;120mbr \u001b[0m\u001b[48;5;120mi \u001b[0m\u001b[48;5;120mlook \u001b[0m\u001b[48;5;120mforward \u001b[0m\u001b[48;5;120mto \u001b[0m\u001b[48;5;120mbetter \u001b[0m\u001b[48;5;120mproduced \u001b[0m\u001b[48;5;120mmovie \u001b[0m\u001b[48;5;120mentertainment \u001b[0m\n",
      "\u001b[48;5;120mbr \u001b[0m\u001b[48;5;120mbr \u001b[0m\u001b[48;5;120min \u001b[0m\u001b[48;5;120mthis \u001b[0m\u001b[48;5;120mcase \u001b[0m\n",
      "\u001b[48;5;120mi \u001b[0m\u001b[48;5;120mrather \u001b[0m\u001b[48;5;120msee \u001b[0m\u001b[48;5;120mthe \u001b[0m\u001b[48;5;120mplay \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "with tf.Session(config=config) as s:\n",
    "    model, saver = HAN_model_1(s)\n",
    "    tflog_dir = 'tf_logs'\n",
    "    summary_writer = tf.summary.FileWriter(tflog_dir, graph=tf.get_default_graph())\n",
    "    \n",
    "    data, labels_batch, sent_per_doc,\\\n",
    "    words_per_sent_per_doc, sents_batch = next(batches_split)\n",
    "\n",
    "    fd = {\n",
    "        model.is_training: True,\n",
    "        model.inputs_embedded: data,\n",
    "        model.word_lengths: words_per_sent_per_doc,\n",
    "        model.sentence_lengths: sent_per_doc,\n",
    "        model.labels: labels_batch,\n",
    "        model.sample_weights: np.ones(shape=(10))\n",
    "    }\n",
    "\n",
    "    word_attentions, sent_attentions = s.run([model.word_attentions, \n",
    "                                              model.sent_attentions], \n",
    "                                             feed_dict=fd)\n",
    "    \n",
    "    sent_atts = sent_attentions[0]\n",
    "    sents = sents_batch[0]\n",
    "    \n",
    "    max_sent_att = 0\n",
    "    max_word_att = 0\n",
    "    \n",
    "    for sent_index in range(len(sents)):\n",
    "        max_sent_att = max(max_sent_att, sent_atts[sent_index])\n",
    "        \n",
    "        for word_index in range(len(sents[sent_index])):\n",
    "            max_word_att = max(max_word_att, word_attentions[sent_index][word_index])\n",
    "    \n",
    "    def draw_highlighted_att(max_sent_att_loc, max_word_att_loc):\n",
    "        for sent_index in range(len(sents)):\n",
    "            for word_index in range(len(sents[sent_index])):\n",
    "                intsty = 2 - int(word_attentions[sent_index][word_index] / max_word_att_loc * 5)\n",
    "                print_color(sents[sent_index][word_index], bg=rgb(2, 5, intsty), end=' ') \n",
    "            print()\n",
    "    \n",
    "    draw_highlighted_att(max_sent_att, max_word_att)\n",
    "    print()\n",
    "    draw_highlighted_att(1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model parameters from checkpoints/checkpoint-240\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/checkpoint-240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0228bd9a95de4d52bfa6e870f0255cfd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-300b4a2a6c4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             }\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_attentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_attentions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options)\n",
    "\n",
    "good_true = list()\n",
    "good_false = list()\n",
    "bad_false = list()\n",
    "bad_true = list()\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    with tf.Session(config=config) as sess:\n",
    "        model, saver = HAN_model_1(sess, True)\n",
    "\n",
    "        \n",
    "        for i, (data, labels_batch, sent_per_doc, words_per_sent_per_doc, sents_b) in  tqdm.tqdm_notebook(enumerate(batches_split), total=max_iters):\n",
    "            fd = {\n",
    "                model.is_training: True,\n",
    "                model.inputs_embedded: data,\n",
    "                model.word_lengths: words_per_sent_per_doc,\n",
    "                model.sentence_lengths: sent_per_doc,\n",
    "                model.labels: labels_batch,\n",
    "                model.sample_weights: np.ones(shape=(10))\n",
    "            }\n",
    "\n",
    "            words, sentences = sess.run([model.word_attentions, model.sent_attentions], feed_dict=fd)\n",
    "\n",
    "            for bt in range(len(sents_b)):\n",
    "                for sent_num in range(len(sents_b[bt])):\n",
    "                    for g in range(len(sents_b[bt][sent_num])):\n",
    "                        val = words[bt * len(sentences[0]) + sent_num][g]\n",
    "                        if (sents_b[bt][sent_num][g] == 'good'):\n",
    "                            if labels_batch[bt] == True:\n",
    "                                good_true.append(val)\n",
    "                            else:\n",
    "                                good_false.append(val)\n",
    "\n",
    "                        if (sents_b[bt][sent_num][g] == 'bad'):\n",
    "                            if labels_batch[bt] == True:\n",
    "                                bad_true.append(val)\n",
    "                            else:\n",
    "                                bad_false.append(val)\n",
    "\n",
    "            if (i >= max_iters):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def serialize(name, cont):\n",
    "    with open(name, 'wb') as handle:\n",
    "        pickle.dump(cont, handle)\n",
    "        \n",
    "serialize('goods_at_pos.pickle', good_true)\n",
    "serialize('goods_at_neg.pickle', good_false)\n",
    "serialize('bads_at_pos.pickle', bad_true)\n",
    "serialize('bads_at_neg.pickle', bad_false)\n",
    "\n",
    "def deserialize(name):\n",
    "    with open(name, 'rb') as handle:\n",
    "        return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.00726543], dtype=float32),\n",
       " array([ 0.01889882], dtype=float32),\n",
       " array([ 0.02065516], dtype=float32),\n",
       " array([ 0.019372], dtype=float32),\n",
       " array([ 0.03000282], dtype=float32),\n",
       " array([ 0.02861412], dtype=float32),\n",
       " array([ 0.02544498], dtype=float32),\n",
       " array([ 0.02080377], dtype=float32),\n",
       " array([ 0.01643308], dtype=float32),\n",
       " array([ 0.01531842], dtype=float32),\n",
       " array([ 0.0157626], dtype=float32),\n",
       " array([ 0.01460765], dtype=float32),\n",
       " array([ 0.01076812], dtype=float32),\n",
       " array([ 0.01639987], dtype=float32),\n",
       " array([ 0.01444027], dtype=float32),\n",
       " array([ 0.01621926], dtype=float32),\n",
       " array([ 0.01356594], dtype=float32),\n",
       " array([ 0.01102889], dtype=float32),\n",
       " array([ 0.01235709], dtype=float32),\n",
       " array([ 0.00581179], dtype=float32),\n",
       " array([ 0.00715643], dtype=float32),\n",
       " array([ 0.00742047], dtype=float32),\n",
       " array([ 0.00657258], dtype=float32),\n",
       " array([ 0.00705202], dtype=float32),\n",
       " array([ 0.0165693], dtype=float32),\n",
       " array([ 0.0194462], dtype=float32),\n",
       " array([ 0.0179923], dtype=float32),\n",
       " array([ 0.01707413], dtype=float32),\n",
       " array([ 0.01818251], dtype=float32),\n",
       " array([ 0.01863434], dtype=float32),\n",
       " array([ 0.01890939], dtype=float32),\n",
       " array([ 0.01715536], dtype=float32),\n",
       " array([ 0.01570607], dtype=float32),\n",
       " array([ 0.01970595], dtype=float32),\n",
       " array([ 0.01688726], dtype=float32),\n",
       " array([ 0.00824909], dtype=float32),\n",
       " array([ 0.01071078], dtype=float32),\n",
       " array([ 0.02093067], dtype=float32),\n",
       " array([ 0.02013439], dtype=float32),\n",
       " array([ 0.02194487], dtype=float32),\n",
       " array([ 0.02244722], dtype=float32),\n",
       " array([ 0.02249471], dtype=float32),\n",
       " array([ 0.01392608], dtype=float32),\n",
       " array([ 0.01847677], dtype=float32),\n",
       " array([ 0.01479944], dtype=float32),\n",
       " array([ 0.01169535], dtype=float32),\n",
       " array([ 0.02141482], dtype=float32),\n",
       " array([ 0.01652207], dtype=float32),\n",
       " array([ 0.01780593], dtype=float32),\n",
       " array([ 0.0160692], dtype=float32),\n",
       " array([ 0.01557762], dtype=float32),\n",
       " array([ 0.01562606], dtype=float32),\n",
       " array([ 0.02028493], dtype=float32),\n",
       " array([ 0.01903502], dtype=float32),\n",
       " array([ 0.01699398], dtype=float32),\n",
       " array([ 0.01068848], dtype=float32),\n",
       " array([ 0.01892627], dtype=float32),\n",
       " array([ 0.01245797], dtype=float32),\n",
       " array([ 0.01239606], dtype=float32),\n",
       " array([ 0.01084989], dtype=float32),\n",
       " array([ 0.01168028], dtype=float32),\n",
       " array([ 0.00836216], dtype=float32),\n",
       " array([ 0.00886509], dtype=float32),\n",
       " array([ 0.00775878], dtype=float32),\n",
       " array([ 0.01089774], dtype=float32),\n",
       " array([ 0.00924393], dtype=float32),\n",
       " array([ 0.00985097], dtype=float32),\n",
       " array([ 0.01083257], dtype=float32),\n",
       " array([ 0.01000159], dtype=float32),\n",
       " array([ 0.0190052], dtype=float32),\n",
       " array([ 0.01971344], dtype=float32),\n",
       " array([ 0.02193846], dtype=float32),\n",
       " array([ 0.0135522], dtype=float32),\n",
       " array([ 0.00985483], dtype=float32),\n",
       " array([ 0.01926887], dtype=float32),\n",
       " array([ 0.01193942], dtype=float32),\n",
       " array([ 0.01422542], dtype=float32),\n",
       " array([ 0.01285752], dtype=float32),\n",
       " array([ 0.01232982], dtype=float32),\n",
       " array([ 0.01004868], dtype=float32),\n",
       " array([ 0.01580323], dtype=float32),\n",
       " array([ 0.02006422], dtype=float32),\n",
       " array([ 0.01895016], dtype=float32),\n",
       " array([ 0.02459963], dtype=float32),\n",
       " array([ 0.01829296], dtype=float32),\n",
       " array([ 0.01954817], dtype=float32),\n",
       " array([ 0.01873942], dtype=float32),\n",
       " array([ 0.01506679], dtype=float32),\n",
       " array([ 0.01473643], dtype=float32),\n",
       " array([ 0.01696132], dtype=float32),\n",
       " array([ 0.01750438], dtype=float32),\n",
       " array([ 0.02035998], dtype=float32),\n",
       " array([ 0.02023656], dtype=float32),\n",
       " array([ 0.02059391], dtype=float32),\n",
       " array([ 0.01594166], dtype=float32),\n",
       " array([ 0.01724134], dtype=float32),\n",
       " array([ 0.02058824], dtype=float32),\n",
       " array([ 0.01897903], dtype=float32),\n",
       " array([ 0.02190723], dtype=float32),\n",
       " array([ 0.03101083], dtype=float32),\n",
       " array([ 0.01574837], dtype=float32),\n",
       " array([ 0.02214137], dtype=float32),\n",
       " array([ 0.0222021], dtype=float32),\n",
       " array([ 0.02542487], dtype=float32),\n",
       " array([ 0.01862772], dtype=float32),\n",
       " array([ 0.02497869], dtype=float32),\n",
       " array([ 0.01865938], dtype=float32),\n",
       " array([ 0.01929528], dtype=float32),\n",
       " array([ 0.01343594], dtype=float32),\n",
       " array([ 0.01435541], dtype=float32),\n",
       " array([ 0.01583013], dtype=float32),\n",
       " array([ 0.01394606], dtype=float32),\n",
       " array([ 0.0144195], dtype=float32),\n",
       " array([ 0.01630589], dtype=float32),\n",
       " array([ 0.01573027], dtype=float32),\n",
       " array([ 0.01496152], dtype=float32),\n",
       " array([ 0.01085834], dtype=float32),\n",
       " array([ 0.00968014], dtype=float32),\n",
       " array([ 0.01767975], dtype=float32),\n",
       " array([ 0.01571371], dtype=float32),\n",
       " array([ 0.01437513], dtype=float32),\n",
       " array([ 0.01559954], dtype=float32),\n",
       " array([ 0.01520511], dtype=float32),\n",
       " array([ 0.01632264], dtype=float32),\n",
       " array([ 0.01643593], dtype=float32),\n",
       " array([ 0.0145582], dtype=float32),\n",
       " array([ 0.01588598], dtype=float32),\n",
       " array([ 0.0149365], dtype=float32),\n",
       " array([ 0.01793267], dtype=float32),\n",
       " array([ 0.01982255], dtype=float32),\n",
       " array([ 0.0144705], dtype=float32),\n",
       " array([ 0.01582649], dtype=float32),\n",
       " array([ 0.00784822], dtype=float32),\n",
       " array([ 0.01417998], dtype=float32),\n",
       " array([ 0.01682092], dtype=float32),\n",
       " array([ 0.00953393], dtype=float32),\n",
       " array([ 0.0037166], dtype=float32),\n",
       " array([ 0.01153889], dtype=float32),\n",
       " array([ 0.01087186], dtype=float32),\n",
       " array([ 0.00903103], dtype=float32),\n",
       " array([ 0.01401332], dtype=float32),\n",
       " array([ 0.01154332], dtype=float32),\n",
       " array([ 0.01226004], dtype=float32),\n",
       " array([ 0.00884669], dtype=float32),\n",
       " array([ 0.0101273], dtype=float32),\n",
       " array([ 0.0117619], dtype=float32),\n",
       " array([ 0.01178493], dtype=float32),\n",
       " array([ 0.01016757], dtype=float32),\n",
       " array([ 0.01020519], dtype=float32),\n",
       " array([ 0.01231307], dtype=float32),\n",
       " array([ 0.01101821], dtype=float32),\n",
       " array([ 0.01007311], dtype=float32),\n",
       " array([ 0.01367587], dtype=float32),\n",
       " array([ 0.01152936], dtype=float32),\n",
       " array([ 0.01998569], dtype=float32),\n",
       " array([ 0.0258879], dtype=float32),\n",
       " array([ 0.02400581], dtype=float32),\n",
       " array([ 0.01656784], dtype=float32),\n",
       " array([ 0.01240336], dtype=float32),\n",
       " array([ 0.01296537], dtype=float32),\n",
       " array([ 0.01499372], dtype=float32),\n",
       " array([ 0.01317456], dtype=float32),\n",
       " array([ 0.02225077], dtype=float32),\n",
       " array([ 0.01572398], dtype=float32),\n",
       " array([ 0.01682208], dtype=float32),\n",
       " array([ 0.00998894], dtype=float32),\n",
       " array([ 0.01213992], dtype=float32),\n",
       " array([ 0.00961144], dtype=float32),\n",
       " array([ 0.00605384], dtype=float32),\n",
       " array([ 0.00503868], dtype=float32),\n",
       " array([ 0.0056905], dtype=float32),\n",
       " array([ 0.00421133], dtype=float32),\n",
       " array([ 0.00402348], dtype=float32),\n",
       " array([ 0.00338001], dtype=float32),\n",
       " array([ 0.0044925], dtype=float32),\n",
       " array([ 0.02272225], dtype=float32),\n",
       " array([ 0.00821258], dtype=float32),\n",
       " array([ 0.00654664], dtype=float32),\n",
       " array([ 0.00638058], dtype=float32),\n",
       " array([ 0.00810399], dtype=float32),\n",
       " array([ 0.02165335], dtype=float32),\n",
       " array([ 0.01975936], dtype=float32),\n",
       " array([ 0.02529522], dtype=float32),\n",
       " array([ 0.02396639], dtype=float32),\n",
       " array([ 0.03164438], dtype=float32),\n",
       " array([ 0.01137576], dtype=float32),\n",
       " array([ 0.01518885], dtype=float32),\n",
       " array([ 0.01332683], dtype=float32),\n",
       " array([ 0.01237199], dtype=float32),\n",
       " array([ 0.01548509], dtype=float32),\n",
       " array([ 0.01996763], dtype=float32),\n",
       " array([ 0.01736831], dtype=float32),\n",
       " array([ 0.01143881], dtype=float32),\n",
       " array([ 0.01577421], dtype=float32),\n",
       " array([ 0.00977943], dtype=float32),\n",
       " array([ 0.01334544], dtype=float32),\n",
       " array([ 0.01044631], dtype=float32),\n",
       " array([ 0.01095423], dtype=float32),\n",
       " array([ 0.01308888], dtype=float32),\n",
       " array([ 0.02073536], dtype=float32),\n",
       " array([ 0.0236443], dtype=float32),\n",
       " array([ 0.01505411], dtype=float32),\n",
       " array([ 0.01560111], dtype=float32),\n",
       " array([ 0.01602615], dtype=float32),\n",
       " array([ 0.02263903], dtype=float32),\n",
       " array([ 0.02201316], dtype=float32),\n",
       " array([ 0.02028911], dtype=float32),\n",
       " array([ 0.0195616], dtype=float32),\n",
       " array([ 0.01193597], dtype=float32),\n",
       " array([ 0.01171696], dtype=float32),\n",
       " array([ 0.01197674], dtype=float32),\n",
       " array([ 0.00963265], dtype=float32),\n",
       " array([ 0.01233964], dtype=float32),\n",
       " array([ 0.0078107], dtype=float32),\n",
       " array([ 0.00660026], dtype=float32),\n",
       " array([ 0.01030151], dtype=float32),\n",
       " array([ 0.01661133], dtype=float32),\n",
       " array([ 0.00316174], dtype=float32),\n",
       " array([ 0.00313189], dtype=float32),\n",
       " array([ 0.00248393], dtype=float32),\n",
       " array([ 0.00868368], dtype=float32),\n",
       " array([ 0.00766146], dtype=float32),\n",
       " array([ 0.00557129], dtype=float32),\n",
       " array([ 0.0068547], dtype=float32),\n",
       " array([ 0.01826603], dtype=float32),\n",
       " array([ 0.01792021], dtype=float32),\n",
       " array([ 0.01711974], dtype=float32),\n",
       " array([ 0.01371109], dtype=float32),\n",
       " array([ 0.01573838], dtype=float32),\n",
       " array([ 0.01735874], dtype=float32),\n",
       " array([ 0.01395267], dtype=float32),\n",
       " array([ 0.01466354], dtype=float32),\n",
       " array([ 0.02436485], dtype=float32),\n",
       " array([ 0.01848024], dtype=float32),\n",
       " array([ 0.01526978], dtype=float32),\n",
       " array([ 0.01967087], dtype=float32),\n",
       " array([ 0.01754273], dtype=float32),\n",
       " array([ 0.01876677], dtype=float32),\n",
       " array([ 0.01529958], dtype=float32),\n",
       " array([ 0.02020727], dtype=float32),\n",
       " array([ 0.01766274], dtype=float32),\n",
       " array([ 0.02021532], dtype=float32),\n",
       " array([ 0.01862924], dtype=float32),\n",
       " array([ 0.0176296], dtype=float32),\n",
       " array([ 0.01386262], dtype=float32),\n",
       " array([ 0.01316278], dtype=float32),\n",
       " array([ 0.01451061], dtype=float32),\n",
       " array([ 0.01549915], dtype=float32),\n",
       " array([ 0.00703934], dtype=float32),\n",
       " array([ 0.00826256], dtype=float32),\n",
       " array([ 0.01489091], dtype=float32),\n",
       " array([ 0.01332675], dtype=float32),\n",
       " array([ 0.01400269], dtype=float32),\n",
       " array([ 0.0142965], dtype=float32),\n",
       " array([ 0.01271873], dtype=float32),\n",
       " array([ 0.01910638], dtype=float32),\n",
       " array([ 0.01397489], dtype=float32),\n",
       " array([ 0.01418473], dtype=float32),\n",
       " array([ 0.01733252], dtype=float32),\n",
       " array([ 0.01519433], dtype=float32),\n",
       " array([ 0.01280034], dtype=float32),\n",
       " array([ 0.01309413], dtype=float32),\n",
       " array([ 0.01264883], dtype=float32),\n",
       " array([ 0.01602351], dtype=float32),\n",
       " array([ 0.02132821], dtype=float32),\n",
       " array([ 0.01689002], dtype=float32),\n",
       " array([ 0.01813817], dtype=float32),\n",
       " array([ 0.01676909], dtype=float32),\n",
       " array([ 0.01521988], dtype=float32),\n",
       " array([ 0.01533959], dtype=float32),\n",
       " array([ 0.0144593], dtype=float32),\n",
       " array([ 0.01135729], dtype=float32),\n",
       " array([ 0.01676782], dtype=float32),\n",
       " array([ 0.01937727], dtype=float32),\n",
       " array([ 0.00896376], dtype=float32),\n",
       " array([ 0.00960149], dtype=float32),\n",
       " array([ 0.00912457], dtype=float32),\n",
       " array([ 0.01471407], dtype=float32),\n",
       " array([ 0.01030208], dtype=float32),\n",
       " array([ 0.01105699], dtype=float32),\n",
       " array([ 0.01771702], dtype=float32),\n",
       " array([ 0.01656892], dtype=float32),\n",
       " array([ 0.01555807], dtype=float32),\n",
       " array([ 0.01306526], dtype=float32),\n",
       " array([ 0.01577308], dtype=float32),\n",
       " array([ 0.01230304], dtype=float32),\n",
       " array([ 0.01992458], dtype=float32),\n",
       " array([ 0.02829764], dtype=float32),\n",
       " array([ 0.01797449], dtype=float32),\n",
       " array([ 0.01667785], dtype=float32),\n",
       " array([ 0.01506435], dtype=float32),\n",
       " array([ 0.02009864], dtype=float32),\n",
       " array([ 0.01882817], dtype=float32),\n",
       " array([ 0.01864661], dtype=float32),\n",
       " array([ 0.01835053], dtype=float32),\n",
       " array([ 0.01582544], dtype=float32),\n",
       " array([ 0.01679356], dtype=float32),\n",
       " array([ 0.0143988], dtype=float32),\n",
       " array([ 0.01832906], dtype=float32),\n",
       " array([ 0.01315359], dtype=float32),\n",
       " array([ 0.01588801], dtype=float32),\n",
       " array([ 0.02027165], dtype=float32),\n",
       " array([ 0.02365801], dtype=float32),\n",
       " array([ 0.01740429], dtype=float32),\n",
       " array([ 0.01021469], dtype=float32),\n",
       " array([ 0.00903572], dtype=float32),\n",
       " array([ 0.01625066], dtype=float32),\n",
       " array([ 0.01543401], dtype=float32),\n",
       " array([ 0.01340864], dtype=float32),\n",
       " array([ 0.0161892], dtype=float32),\n",
       " array([ 0.013733], dtype=float32),\n",
       " array([ 0.01183879], dtype=float32),\n",
       " array([ 0.01402283], dtype=float32),\n",
       " array([ 0.01527873], dtype=float32),\n",
       " array([ 0.01436287], dtype=float32),\n",
       " array([ 0.01307213], dtype=float32),\n",
       " array([ 0.01392067], dtype=float32),\n",
       " array([ 0.01313008], dtype=float32),\n",
       " array([ 0.01499886], dtype=float32),\n",
       " array([ 0.01431186], dtype=float32),\n",
       " array([ 0.01428142], dtype=float32),\n",
       " array([ 0.01387645], dtype=float32),\n",
       " array([ 0.01529428], dtype=float32),\n",
       " array([ 0.01295012], dtype=float32),\n",
       " array([ 0.01671784], dtype=float32),\n",
       " array([ 0.01473252], dtype=float32),\n",
       " array([ 0.01429571], dtype=float32),\n",
       " array([ 0.01477973], dtype=float32),\n",
       " array([ 0.02080524], dtype=float32),\n",
       " array([ 0.01828728], dtype=float32),\n",
       " array([ 0.01483755], dtype=float32),\n",
       " array([ 0.0215503], dtype=float32),\n",
       " array([ 0.01673628], dtype=float32),\n",
       " array([ 0.01999447], dtype=float32),\n",
       " array([ 0.01944112], dtype=float32),\n",
       " array([ 0.01570812], dtype=float32),\n",
       " array([ 0.01824416], dtype=float32),\n",
       " array([ 0.01736028], dtype=float32),\n",
       " array([ 0.01373698], dtype=float32),\n",
       " array([ 0.01648843], dtype=float32),\n",
       " array([ 0.01860648], dtype=float32),\n",
       " array([ 0.01606477], dtype=float32),\n",
       " array([ 0.01690271], dtype=float32),\n",
       " array([ 0.01757553], dtype=float32),\n",
       " array([ 0.00971918], dtype=float32),\n",
       " array([ 0.01067064], dtype=float32),\n",
       " array([ 0.01335248], dtype=float32),\n",
       " array([ 0.0131292], dtype=float32),\n",
       " array([ 0.01165174], dtype=float32),\n",
       " array([ 0.00978877], dtype=float32),\n",
       " array([ 0.01026332], dtype=float32),\n",
       " array([ 0.01400171], dtype=float32),\n",
       " array([ 0.01966185], dtype=float32),\n",
       " array([ 0.01651521], dtype=float32),\n",
       " array([ 0.01240055], dtype=float32),\n",
       " array([ 0.01437294], dtype=float32),\n",
       " array([ 0.01475397], dtype=float32),\n",
       " array([ 0.01761288], dtype=float32),\n",
       " array([ 0.0151423], dtype=float32),\n",
       " array([ 0.01274481], dtype=float32),\n",
       " array([ 0.01260759], dtype=float32),\n",
       " array([ 0.01219948], dtype=float32),\n",
       " array([ 0.0112696], dtype=float32),\n",
       " array([ 0.02289221], dtype=float32),\n",
       " array([ 0.01672233], dtype=float32),\n",
       " array([ 0.02678282], dtype=float32),\n",
       " array([ 0.01902303], dtype=float32),\n",
       " array([ 0.01199107], dtype=float32),\n",
       " array([ 0.00806007], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/matplotlib/font_manager.py:1297: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAJOCAYAAAAkve/mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noGCiDQAAoGD/PwD79NGzAW6tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4cbc0897b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAJOCAYAAAAkve/mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB2+YGJpnTrosAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c9df75cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_hist(pos, neg, word):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.distplot(pos, kde=False, color='lightblue',  label='{} in positives'.format(word))\n",
    "    sns.distplot(neg, kde=False,  color='salmon',   label='{} in negatives'.format(word))\n",
    "    plt.title(word)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "draw_hist(good_true, good_false, 'good')\n",
    "draw_hist(bad_true, bad_false, 'bad')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model parameters from checkpoints/checkpoint-240\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/checkpoint-240\n",
      "batch 0 accuracy is 0.7000\n",
      "batch 1 accuracy is 0.6000\n",
      "batch 2 accuracy is 0.6667\n",
      "batch 3 accuracy is 0.7000\n",
      "batch 4 accuracy is 0.7000\n",
      "batch 5 accuracy is 0.7000\n",
      "batch 6 accuracy is 0.7143\n",
      "batch 7 accuracy is 0.7125\n",
      "batch 8 accuracy is 0.7000\n",
      "batch 9 accuracy is 0.7300\n",
      "batch 10 accuracy is 0.7455\n",
      "batch 11 accuracy is 0.7417\n",
      "batch 12 accuracy is 0.7385\n",
      "batch 13 accuracy is 0.7357\n",
      "batch 14 accuracy is 0.7267\n",
      "batch 15 accuracy is 0.7312\n",
      "batch 16 accuracy is 0.7353\n",
      "batch 17 accuracy is 0.7278\n",
      "batch 18 accuracy is 0.7211\n",
      "batch 19 accuracy is 0.7250\n",
      "batch 20 accuracy is 0.7286\n",
      "batch 21 accuracy is 0.7318\n",
      "batch 22 accuracy is 0.7304\n",
      "batch 23 accuracy is 0.7250\n",
      "batch 24 accuracy is 0.7320\n",
      "batch 25 accuracy is 0.7269\n",
      "batch 26 accuracy is 0.7296\n",
      "batch 27 accuracy is 0.7214\n",
      "batch 28 accuracy is 0.7310\n",
      "batch 29 accuracy is 0.7300\n",
      "batch 30 accuracy is 0.7323\n",
      "batch 31 accuracy is 0.7281\n",
      "batch 32 accuracy is 0.7273\n",
      "batch 33 accuracy is 0.7294\n",
      "batch 34 accuracy is 0.7314\n",
      "batch 35 accuracy is 0.7306\n",
      "batch 36 accuracy is 0.7324\n",
      "batch 37 accuracy is 0.7289\n",
      "batch 38 accuracy is 0.7282\n",
      "batch 39 accuracy is 0.7300\n",
      "batch 40 accuracy is 0.7341\n",
      "batch 41 accuracy is 0.7381\n",
      "batch 42 accuracy is 0.7395\n",
      "batch 43 accuracy is 0.7364\n",
      "batch 44 accuracy is 0.7400\n",
      "batch 45 accuracy is 0.7370\n",
      "batch 46 accuracy is 0.7383\n",
      "batch 47 accuracy is 0.7375\n",
      "batch 48 accuracy is 0.7388\n",
      "batch 49 accuracy is 0.7340\n",
      "batch 50 accuracy is 0.7333\n",
      "batch 51 accuracy is 0.7327\n",
      "batch 52 accuracy is 0.7302\n",
      "batch 53 accuracy is 0.7333\n",
      "batch 54 accuracy is 0.7345\n",
      "batch 55 accuracy is 0.7375\n",
      "batch 56 accuracy is 0.7368\n",
      "batch 57 accuracy is 0.7379\n",
      "batch 58 accuracy is 0.7390\n",
      "batch 59 accuracy is 0.7367\n",
      "batch 60 accuracy is 0.7361\n",
      "batch 61 accuracy is 0.7387\n",
      "batch 62 accuracy is 0.7413\n",
      "batch 63 accuracy is 0.7438\n",
      "batch 64 accuracy is 0.7415\n",
      "batch 65 accuracy is 0.7424\n",
      "batch 66 accuracy is 0.7358\n",
      "batch 67 accuracy is 0.7353\n",
      "batch 68 accuracy is 0.7333\n",
      "batch 69 accuracy is 0.7329\n",
      "batch 70 accuracy is 0.7310\n",
      "batch 71 accuracy is 0.7292\n",
      "batch 72 accuracy is 0.7301\n",
      "batch 73 accuracy is 0.7297\n",
      "batch 74 accuracy is 0.7293\n",
      "batch 75 accuracy is 0.7303\n",
      "batch 76 accuracy is 0.7338\n",
      "batch 77 accuracy is 0.7346\n",
      "batch 78 accuracy is 0.7329\n",
      "batch 79 accuracy is 0.7325\n",
      "batch 80 accuracy is 0.7333\n",
      "batch 81 accuracy is 0.7354\n",
      "batch 82 accuracy is 0.7361\n",
      "batch 83 accuracy is 0.7369\n",
      "batch 84 accuracy is 0.7388\n",
      "batch 85 accuracy is 0.7407\n",
      "batch 86 accuracy is 0.7425\n",
      "batch 87 accuracy is 0.7443\n",
      "batch 88 accuracy is 0.7438\n",
      "batch 89 accuracy is 0.7433\n",
      "batch 90 accuracy is 0.7440\n",
      "batch 91 accuracy is 0.7446\n",
      "batch 92 accuracy is 0.7462\n",
      "batch 93 accuracy is 0.7468\n",
      "batch 94 accuracy is 0.7484\n",
      "batch 95 accuracy is 0.7500\n",
      "batch 96 accuracy is 0.7515\n",
      "batch 97 accuracy is 0.7520\n",
      "batch 98 accuracy is 0.7515\n",
      "batch 99 accuracy is 0.7530\n",
      "batch 100 accuracy is 0.7515\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "trues = 0\n",
    "alls = 0\n",
    "\n",
    "with tf.Session(config=config) as s:\n",
    "    model, saver = HAN_model_1(s)\n",
    "    tflog_dir = 'tf_logs'\n",
    "    summary_writer = tf.summary.FileWriter(tflog_dir, graph=tf.get_default_graph())\n",
    "    \n",
    "    for i, (data, labels_batch, sent_per_doc, words_per_sent_per_doc, sents_batch) in enumerate(batches_split):\n",
    "\n",
    "        fd = {\n",
    "            model.is_training: True,\n",
    "            model.inputs_embedded: data,\n",
    "            model.word_lengths: words_per_sent_per_doc,\n",
    "            model.sentence_lengths: sent_per_doc,\n",
    "            model.labels: labels_batch,\n",
    "            model.sample_weights: np.ones(shape=(10))\n",
    "        }\n",
    "\n",
    "        preds = s.run(model.prediction, feed_dict=fd)\n",
    "        \n",
    "        corrects = (labels_batch == preds).sum()\n",
    "        \n",
    "        trues += corrects\n",
    "        alls += len(labels_batch)\n",
    "        \n",
    "        print('batch {} accuracy is {:.4f}'.format(i, trues / alls))\n",
    "        \n",
    "        if i == 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751485148515\n"
     ]
    }
   ],
   "source": [
    "print(1.*trues/alls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
